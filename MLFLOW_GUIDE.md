# MLflow Training Pipeline & Deployment Guide

## ğŸš€ Quick Start

### 1. Install Dependencies
```bash
pip install -r requirements.txt
```

### 2. Train Model with MLflow
```bash
cd src
python train.py --k-folds 10
```

### 3. View MLflow UI
```bash
mlflow ui
# Open http://localhost:5000
```

### 4. Run API Locally
```bash
cd src
uvicorn src.api.main:app --reload
# Open http://localhost:8000/docs
```

---

## ğŸ“Š What Does train.py Do?

The `train.py` script is a production-ready MLflow-integrated training pipeline that:

### âœ… Training Steps

1. **Load Data**: Loads and preprocesses the breast cancer dataset
2. **Build Model**: Creates Logistic Regression pipeline with StandardScaler
3. **K-Fold Cross-Validation**: Validates model stability across data splits
4. **Train Final Model**: Trains on full training set
5. **Evaluate on Test Set**: Comprehensive metrics on held-out test data
6. **Save Model Artifacts**: Saves model as MLflow artifact
7. **Log Everything to MLflow**: All parameters, metrics, and artifacts

### ğŸ“ What Gets Logged to MLflow

#### Parameters
- `model_type`: "LogisticRegression"
- `k_folds`: Number of CV folds (default: 10)
- `lr_*`: Logistic regression hyperparameters
- `random_state`: Random seed for reproducibility
- `data_version`: SHA256 hash of dataset file
- `n_samples_train`, `n_samples_test`, `n_features`: Dataset info

#### Metrics
**Cross-Validation (mean Â± std):**
- `cv_accuracy_mean`, `cv_accuracy_std`
- `cv_precision_mean`, `cv_precision_std`
- `cv_recall_mean`, `cv_recall_std`
- `cv_f1_mean`, `cv_f1_std`

**Test Set:**
- `test_accuracy`
- `test_precision`
- `test_recall`
- `test_f1`
- `test_roc_auc`

**Promotion:**
- `promoted`: 1 if promoted, 0 if not

#### Artifacts
- **confusion_matrix.png**: Visual confusion matrix
- **classification_report.txt**: Detailed classification metrics
- **run_summary.json**: JSON summary for CI/CD
- **model/**: Serialized model pipeline

---

## ğŸ† Model Promotion Logic

Models are **automatically promoted** to `models/latest/` if they meet:

### Promotion Thresholds (configurable in `utils/config.py`)
```python
MODEL_PROMOTION_THRESHOLDS = {
    'min_recall': 0.95,        # â‰¥ 95% recall (critical for medical diagnosis)
    'max_recall_std': 0.05,    # â‰¤ 5% std (stability requirement)
}
```

### What Happens on Promotion?
1. Model artifacts copied to `models/latest/`
2. Includes: model, confusion matrix, report, summary
3. `promotion_metadata.json` created with timestamp and run ID
4. Ready for deployment!

### What If Model Doesn't Meet Criteria?
- Run still logged to MLflow
- Model **not promoted** to `latest/`
- CI/CD deployment blocked (prevents bad models reaching production)

---

## ğŸ”§ CLI Options

```bash
# Normal training (10-fold CV)
python train.py

# Custom number of folds
python train.py --k-folds 5

# Smoke test (20% of data, 3 folds, fast)
python train.py --smoke --k-folds 3
```

---

## ğŸ³ Docker & Deployment

### Build Docker Image
```bash
docker build -t breast-cancer-api -f deployment/Dockerfile .
```

### Run Container Locally
```bash
docker run -p 8000:8000 breast-cancer-api
```

### Test API
```bash
curl -X POST "http://localhost:8000/predict" \
  -H "Content-Type: application/json" \
  -d '{
    "features": [17.99, 10.38, 122.8, 1001.0, 0.1184, 0.2776, 0.3001, 0.1471,
                 0.2419, 0.07871, 1.095, 0.9053, 8.589, 153.4, 0.006399, 0.04904,
                 0.05373, 0.01587, 0.03003, 0.006193, 25.38, 17.33, 184.6, 2019.0,
                 0.1622, 0.6656, 0.7119, 0.2654, 0.4601, 0.1189]
  }'
```

---

## ğŸ”„ CI/CD Pipelines

### CI Pipeline (`.github/workflows/ci.yml`)

**Triggers:** PR, push to main/develop

**Steps:**
1. âœ… Install dependencies
2. âœ… Code quality checks (black, isort, flake8)
3. âœ… Run unit tests with coverage
4. âœ… Smoke test training (`--smoke --k-folds 3`)
5. âœ… Validate artifacts produced
6. âœ… Upload artifacts to GitHub

### CD Pipeline (`.github/workflows/cd.yml`)

**Triggers:** Git tags (`v*.*.*`), manual dispatch

**Steps:**
1. âœ… Full training pipeline
2. âœ… Check promotion status
3. âœ… Build Docker image (if promoted)
4. âœ… Push to AWS ECR (if promoted)
5. âœ… Deploy to ECS/Beanstalk (optional, controlled by flag)
6. âœ… Create GitHub release with artifacts

**Key Feature:** CD only deploys if model meets promotion criteria!

---

## â˜ï¸ AWS Deployment Options

### Option 1: Elastic Beanstalk (Simplest)
âœ… Easiest to set up
âœ… Auto-scaling built-in
âœ… Health monitoring
âœ… Best for small-medium workloads

### Option 2: ECS Fargate (Recommended)
âœ… More control
âœ… Better for production
âœ… Container orchestration
âœ… Integrates with ALB, CloudWatch

### Option 3: Lambda (Advanced)
âš ï¸ More complex packaging
âœ… Serverless, pay-per-request
âœ… Good for sporadic traffic

**See [DEPLOYMENT.md](deployment/DEPLOYMENT.md) for detailed AWS setup instructions.**

---

## ğŸ§ª Testing

### Run All Tests
```bash
pytest
```

### Run with Coverage
```bash
pytest --cov=src --cov-report=html
```

### Run Specific Test File
```bash
pytest tests/test_training.py -v
```

---

## ğŸ“‚ Project Structure

```
breast-cancer-ml/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ train.py                    # ğŸ¯ Main training pipeline
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â””â”€â”€ main.py                 # FastAPI application
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â”œâ”€â”€ config.py               # Configuration & thresholds
â”‚   â”‚   â”œâ”€â”€ load_data.py
â”‚   â”‚   â”œâ”€â”€ preprocess.py
â”‚   â”‚   â””â”€â”€ evaluate.py             # Includes perform_cross_validation
â”‚   â”œâ”€â”€ training_models/
â”‚   â”‚   â”œâ”€â”€ train_logistic_regression.py
â”‚   â”‚   â”œâ”€â”€ train_decision_tree.py
â”‚   â”‚   â””â”€â”€ train_random_forest.py
â”‚   â””â”€â”€ comparison/
â”‚       â””â”€â”€ *.py                    # Model comparison scripts
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ test_training.py
â”‚   â””â”€â”€ test_api.py
â”œâ”€â”€ deployment/
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ Dockerrun.aws.json
â”‚   â””â”€â”€ DEPLOYMENT.md
â”œâ”€â”€ .github/workflows/
â”‚   â”œâ”€â”€ ci.yml
â”‚   â””â”€â”€ cd.yml
â”œâ”€â”€ models/
â”‚   â””â”€â”€ latest/                     # Promoted models go here
â”œâ”€â”€ mlruns/                         # MLflow tracking data
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ pyproject.toml                  # pytest, black, isort config
â”œâ”€â”€ README.md
â””â”€â”€ MODEL_SELECTION.md
```

---

## ğŸ“ˆ MLflow Workflow

```
1. Run Training
   â””â”€> python train.py

2. Logs Everything
   â”œâ”€> Parameters (hyperparams, data version, etc.)
   â”œâ”€> Metrics (CV + test scores)
   â””â”€> Artifacts (model, plots, reports)

3. Check Promotion Criteria
   â”œâ”€> Recall â‰¥ 0.95? âœ“
   â””â”€> Std â‰¤ 0.05? âœ“

4. If Promoted:
   â”œâ”€> Copy to models/latest/
   â””â”€> Ready for deployment

5. View in MLflow UI
   â””â”€> mlflow ui (http://localhost:5000)
```

---

## ğŸ¯ Key Features

âœ… **Data Versioning**: SHA256 hash logged for every run
âœ… **Reproducibility**: Random seeds, full parameter logging
âœ… **Robust Evaluation**: K-fold CV + test set
âœ… **Automated Promotion**: Only good models reach production
âœ… **CI/CD Integration**: GitHub Actions with smoke tests
âœ… **Production-Ready API**: FastAPI with health checks
âœ… **Docker Support**: Multi-stage builds for efficiency
âœ… **AWS Deployment**: ECR + ECS/Beanstalk ready

---

## ğŸ” Troubleshooting

### Model Not Loading in API
```bash
# Check if model exists
ls models/latest/model

# If not, train first
cd src
python train.py
```

### MLflow UI Not Showing Runs
```bash
# Check tracking directory
ls mlruns/

# Make sure you're in project root
mlflow ui --backend-store-uri file:./src/mlruns
```

### CI Tests Failing
```bash
# Run locally first
pytest tests/ -v

# Check code quality
black --check src/
flake8 src/
```

---

## ğŸ“š Learning Resources

- [MLflow Documentation](https://mlflow.org/docs/latest/index.html)
- [FastAPI Documentation](https://fastapi.tiangolo.com/)
- [AWS ECS Guide](https://docs.aws.amazon.com/ecs/)
- [GitHub Actions](https://docs.github.com/en/actions)

---

## ğŸ¤ Contributing

1. Fork the repository
2. Create feature branch (`git checkout -b feature/amazing-feature`)
3. Commit changes (`git commit -m 'Add amazing feature'`)
4. Push to branch (`git push origin feature/amazing-feature`)
5. Open Pull Request

---

## ğŸ“„ License

This project is for educational purposes.

---

**Author**: ML Pipeline Project
**Dataset**: Wisconsin Breast Cancer Dataset (Kaggle)
